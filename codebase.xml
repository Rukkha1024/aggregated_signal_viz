<directory>aggregated_signal_viz</directory>

<source-tree>
  aggregated_signal_viz
├── check_interpolation.py
├── config.yaml
├── debug_interp.py
├── main.py
├── requirements.txt
└── visualizer.py

</source-tree>

<files>
      <file path="check_interpolation.py">
        ```py
#!/usr/bin/env python3
"""Interpolation 설정 확인 스크립트"""
import numpy as np
import polars as pl
import yaml
from pathlib import Path

# Config 로드
with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

# 데이터 로드
input_file = config["data"]["input_file"]
df = pl.read_csv(input_file)

# ID columns
id_cfg = config["data"]["id_columns"]
subject_col = id_cfg["subject"]
velocity_col = id_cfg["velocity"]
trial_col = id_cfg["trial_num"]
frame_col = id_cfg["frame"]
mocap_col = id_cfg["mocap_frame"]
onset_col = id_cfg["onset"]

# Align frames (visualizer.py의 _load_and_align과 동일)
device_rate = config["data"].get("device_sample_rate", 1000)
mocap_rate = config["data"].get("mocap_sample_rate", 100)
frame_ratio = config["data"].get("frame_ratio") or int(device_rate / mocap_rate)

group_cols = [subject_col, velocity_col, trial_col]
mocap_start = pl.col(mocap_col).min().over(group_cols)
onset_device = (pl.col(onset_col).first().over(group_cols) - mocap_start) * frame_ratio
onset_aligned = pl.col(frame_col) - onset_device

df = df.with_columns([
    onset_device.alias("onset_device_frame"),
    onset_aligned.alias("aligned_frame"),
]).sort(group_cols + ["aligned_frame"])

# Global min/max 계산 (현재 코드의 방식)
frame_min = df.select(pl.col("aligned_frame").min()).item()
frame_max = df.select(pl.col("aligned_frame").max()).item()
target_length = config["interpolation"]["target_length"]

print(f"=== Global Target Axis ===")
print(f"Frame range: {frame_min:.2f} ~ {frame_max:.2f}")
print(f"Target length: {target_length}")
print(f"Global target axis: np.linspace({frame_min:.2f}, {frame_max:.2f}, {target_length})")
print()

# 각 trial의 실제 범위 확인
print(f"=== Individual Trial Ranges (first 10) ===")
groups = df.group_by(group_cols, maintain_order=True)
for i, (key, subdf) in enumerate(groups):
    if i >= 10:  # 처음 10개만 출력
        break
    trial_min = subdf["aligned_frame"].min()
    trial_max = subdf["aligned_frame"].max()
    trial_len = len(subdf)
    print(f"Trial {i+1} ({key[0]}, vel={key[1]}, trial={key[2]}): "
          f"range=[{trial_min:.2f}, {trial_max:.2f}], "
          f"raw_points={trial_len}")

print()
print(f"=== Analysis ===")
print(f"각 trial이 global range [{frame_min:.2f}, {frame_max:.2f}]의 일부만 차지하므로,")
print(f"interpolation 후 각 trial은 {target_length}개보다 적은 유효 포인트를 가질 수 있습니다.")
print(f"(나머지는 NaN으로 채워짐)")

```
      </file>
      <file path="config.yaml">
        ```yaml
# === Data Settings ===
data:
  input_file: "data/processed_emg_data.csv"
  features_file: "data/final_dataset.csv"
  id_columns:
    subject: "subject"
    velocity: "velocity"
    trial: "trial_num"
    frame: "DeviceFrame"
    mocap_frame: "MocapFrame"
    onset: "platform_onset"
    offset: "platform_offset"
    task: "task"
  task_filter: "perturb"
  # Sampling rates and frame ratio (MocapFrame → DeviceFrame)
  device_sample_rate: 1000
  mocap_sample_rate: 100
  frame_ratio: 10

# === Signal Groups ===
signal_groups:
  emg:
    columns: [TA, EHL, MG, SOL, PL, RF, VL, ST, RA, EO, IO, SCM, GM, ESC, EST, ESL]
    grid_layout: [4, 4]
  forceplate:
    columns: [Fx, Fy, Fz]
    grid_layout: [1, 3]
  cop:
    columns: [Cx, Cy]
    grid_layout: [1, 1]

# === Interpolation ===
interpolation:
  enabled: true
  method: "linear"
  target_length: 1000

# === Aggregation Modes ===
aggregation_modes:
  subject_mean:
    enabled: true
    groupby: ["subject"]
    output_dir: "output/subject_mean"
    filename_pattern: "{subject}_mean_{signal_group}.png"
  grand_mean:
    enabled: true
    groupby: []
    output_dir: "output/grand_mean"
    filename_pattern: "grand_mean_{signal_group}.png"
  filtered_mean:
    enabled: true
    filter:
      column: "velocity"
      value: 10.0
    groupby: ["subject"]
    output_dir: "output/filtered_mean"
    filename_pattern: "{subject}_vel10_mean_{signal_group}.png"

# === Window Definitions (relative to platform_onset in ms) ===
windows:
  reference_event: "platform_onset"
  definitions:
    p1:
      start_ms: 0
      end_ms: 200
    p2:
      start_ms: 200
      end_ms: 400
    p3:
      start_ms: 400
      end_ms: 600
    p4:
      start_ms: 600
      end_ms: 800

# === Output Settings ===
output:
  base_dir: "output"

```
      </file>
      <file path="debug_interp.py">
        ```py
#!/usr/bin/env python3
"""실제 interpolation 작동 방식 확인"""
import sys
import numpy as np
import polars as pl
import yaml

# Config 로드
with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

# 데이터 로드
df = pl.read_csv(config["data"]["input_file"])
print(f"전체 데이터: {len(df)} rows")

# ID columns
id_cfg = config["data"]["id_columns"]
frame_ratio = 10  # mocap→device

# Align frames (visualizer.py와 동일)
group_cols = ["subject", "velocity", "trial_num"]
mocap_start = pl.col("MocapFrame").min().over(group_cols)
onset_device = (pl.col("platform_onset").first().over(group_cols) - mocap_start) * frame_ratio
onset_aligned = pl.col("DeviceFrame") - onset_device

df = df.with_columns([
    onset_aligned.alias("aligned_frame"),
])

# Global min/max (현재 코드 방식)
frame_min = df.select(pl.col("aligned_frame").min()).item()
frame_max = df.select(pl.col("aligned_frame").max()).item()
target_length = 1000

print(f"\n=== GLOBAL TARGET AXIS (현재 코드 방식) ===")
print(f"전체 데이터의 aligned_frame 범위: {frame_min:.1f} ~ {frame_max:.1f}")
print(f"Target axis: np.linspace({frame_min:.1f}, {frame_max:.1f}, {target_length})")
print(f"→ 즉, {frame_min:.1f}부터 {frame_max:.1f}까지를 1000개로 나눔")

# 각 trial 확인 (처음 3개만)
print(f"\n=== 개별 TRIAL 범위 (처음 3개) ===")
groups = df.group_by(group_cols, maintain_order=True)

for i, (key, subdf) in enumerate(groups):
    if i >= 3:
        break

    trial_min = subdf["aligned_frame"].min()
    trial_max = subdf["aligned_frame"].max()
    trial_range = trial_max - trial_min

    print(f"\nTrial {i+1}: subject={key[0]}, vel={key[1]}, trial={key[2]}")
    print(f"  이 trial의 aligned_frame 범위: {trial_min:.1f} ~ {trial_max:.1f} (범위: {trial_range:.1f})")
    print(f"  원본 데이터 포인트 수: {len(subdf)}개")

    # Global target axis에서 이 trial이 차지하는 비율
    global_range = frame_max - frame_min
    trial_coverage = trial_range / global_range
    expected_points = int(trial_coverage * target_length)

    print(f"  Global range({global_range:.1f}) 대비 비율: {trial_coverage*100:.1f}%")
    print(f"  → Interpolation 후 예상 유효 포인트: 약 {expected_points}개 (나머지는 NaN)")

print(f"\n=== 문제점 요약 ===")
print(f"현재 방식:")
print(f"  1. 모든 trial의 시간 범위를 합친 [{frame_min:.1f}, {frame_max:.1f}]를 1000개로 나눔")
print(f"  2. 각 trial은 자신의 시간 범위에만 데이터가 있고, 나머지는 NaN")
print(f"  3. 따라서 각 trial은 1000개보다 훨씬 적은 유효 데이터만 가짐")
print(f"\n올바른 방식:")
print(f"  1. 각 trial의 시간 범위를 개별적으로 1000개로 나눔")
print(f"  2. 각 trial이 모두 1000개의 유효 데이터를 가짐")

```
      </file>
      <file path="main.py">
        ```py
from pathlib import Path

from visualizer import AggregatedSignalVisualizer, ensure_output_dirs, parse_args


def main() -> None:
    args = parse_args()
    config_path = Path(args.config)
    visualizer = AggregatedSignalVisualizer(config_path)
    ensure_output_dirs(visualizer.base_dir, visualizer.config)
    visualizer.run(modes=args.modes, signal_groups=args.groups)


if __name__ == "__main__":
    main()

```
      </file>
      <file path="requirements.txt">
        ```txt
polars>=0.20.0
numpy>=1.20.0
matplotlib>=3.5.0
scipy>=1.7.0
PyYAML>=5.0

```
      </file>
      <file path="visualizer.py">
        ```py
from __future__ import annotations

import argparse
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import polars as pl
import yaml
from scipy.interpolate import interp1d

# --- Plot style constants (kept in code per visualization exclusion rule) ---
plt.rcParams["axes.unicode_minus"] = False  # Avoid font warnings for minus symbols.
COMMON_STYLE = {
    "dpi": 300,
    "grid_alpha": 0.3,
    "tick_labelsize": 7,
    "title_fontsize": 20,
    "title_fontweight": "bold",
    "title_pad": 5,
    "label_fontsize": 8,
    "legend_loc": "best",
    "legend_framealpha": 0.8,
    "tight_layout_rect": [0, 0, 1, 0.99],
    "savefig_bbox_inches": "tight",
    "savefig_facecolor": "white",
}

WINDOW_COLORS = {"p1": "#4E79A7", "p2": "#F28E2B", "p3": "#E15759", "p4": "#59A14F"}

EMG_STYLE = {
    "figsize": (12, 6),
    "line_color": "blue",
    "line_width": 0.8,
    "line_alpha": 0.8,
    "window_span_alpha": 0.15,
    "onset_marker": {"color": "red", "linestyle": "--", "linewidth": 1.5},
    "max_marker": {"color": "orange", "linestyle": "--", "linewidth": 1.5},
    "legend_fontsize": 6,
    "x_label": "Frame (onset=0)",
}

FORCEPLATE_STYLE = {
    "figsize": (12, 6),
    "line_colors": {"Fx": "purple", "Fy": "brown", "Fz": "green"},
    "line_width": 0.8,
    "line_alpha": 0.8,
    "window_span_alpha": 0.15,
    "onset_marker": {"color": "red", "linestyle": "--", "linewidth": 1.5},
    "legend_fontsize": 6,
    "x_label": "Frame (onset=0)",
}

COP_STYLE = {
    "figsize": (8, 8),
    "scatter_size": 8,
    "scatter_alpha": 0.7,
    "background_color": "lightgray",
    "background_alpha": 0.3,
    "background_size": 6,
    "max_marker": {
        "size": 80,
        "marker": "*",
        "color": "#ED1C24",
        "edgecolor": "white",
        "linewidth": 1,
        "zorder": 10,
    },
    "legend_fontsize": 5,
    "x_label": "Cx (R+/L-)",
    "y_label": "Cy (A+)",
    "y_invert": True,
}


@dataclass
class AggregatedRecord:
    subject: str
    velocity: float
    trial: int
    data: Dict[str, np.ndarray]

    def get(self, key: str) -> Optional[object]:
        return getattr(self, key, None)


def load_config(config_path: Path) -> Dict:
    with config_path.open("r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def ensure_output_dirs(base_path: Path, config: Dict) -> None:
    for mode_cfg in config.get("aggregation_modes", {}).values():
        out_dir = mode_cfg.get("output_dir")
        if not out_dir:
            continue
        Path(base_path, out_dir).mkdir(parents=True, exist_ok=True)


class AggregatedSignalVisualizer:
    def __init__(self, config_path: Path) -> None:
        self.config_path = Path(config_path)
        self.config = load_config(self.config_path)
        self.base_dir = self.config_path.parent
        self.id_cfg = self.config["data"]["id_columns"]
        self.device_rate = self.config["data"].get("device_sample_rate", 1000)
        mocap_rate = self.config["data"].get("mocap_sample_rate", 100)
        self.frame_ratio = self.config["data"].get("frame_ratio") or int(self.device_rate / mocap_rate)
        self.target_length = int(self.config["interpolation"]["target_length"])
        self.interp_method = self.config["interpolation"]["method"]
        self.target_axis: Optional[np.ndarray] = None
        self.resampled: Dict[str, List[AggregatedRecord]] = {}
        self.window_frames = self._compute_window_frames()
        self.features_df: Optional[pl.DataFrame] = self._load_features()

    def run(
        self,
        modes: Optional[Iterable[str]] = None,
        signal_groups: Optional[Iterable[str]] = None,
    ) -> None:
        selected_modes = set(modes) if modes else None
        selected_groups = set(signal_groups) if signal_groups else None

        df = self._load_and_align()
        self.target_axis = self._build_target_axis(df)
        self.resampled = self._resample_all(df, selected_groups)

        for mode_name, mode_cfg in self.config["aggregation_modes"].items():
            if not mode_cfg.get("enabled", True):
                continue
            if selected_modes and mode_name not in selected_modes:
                continue
            for signal_group in self._signal_group_names(selected_groups):
                self._run_mode(signal_group, mode_name, mode_cfg)

    def _signal_group_names(self, selected_groups: Optional[Iterable[str]]) -> List[str]:
        names = list(self.config["signal_groups"].keys())
        if selected_groups is None:
            return names
        return [n for n in names if n in selected_groups]

    def _load_and_align(self) -> pl.DataFrame:
        input_path = Path(self.config["data"]["input_file"])
        if not input_path.is_absolute():
            input_path = (self.base_dir / input_path).resolve()
        df = pl.read_csv(input_path)
        df = df.rename({c: c.lstrip("\ufeff") for c in df.columns})

        task_col = self.id_cfg.get("task")
        task_filter = self.config["data"].get("task_filter")
        if task_filter and task_col in df.columns:
            df = df.filter(pl.col(task_col) == task_filter)
        if df.is_empty():
            raise ValueError("No data available after applying task or input filters.")

        subject_col = self.id_cfg["subject"]
        velocity_col = self.id_cfg["velocity"]
        trial_col = self.id_cfg["trial"]
        frame_col = self.id_cfg["frame"]
        mocap_col = self.id_cfg["mocap_frame"]
        onset_col = self.id_cfg["onset"]
        offset_col = self.id_cfg["offset"]

        group_cols = [subject_col, velocity_col, trial_col]
        # Align DeviceFrame so platform_onset becomes 0 using mocap→device frame ratio.
        mocap_start = pl.col(mocap_col).min().over(group_cols)
        onset_device = (pl.col(onset_col).first().over(group_cols) - mocap_start) * self.frame_ratio
        onset_aligned = pl.col(frame_col) - onset_device
        offset_rel = (
            (pl.col(offset_col).first().over(group_cols) - pl.col(onset_col).first().over(group_cols))
            * self.frame_ratio
        )

        df = df.with_columns(
            [
                onset_device.alias("onset_device_frame"),
                onset_aligned.alias("aligned_frame"),
                offset_rel.alias("offset_from_onset"),
            ]
        ).sort(group_cols + ["aligned_frame"])
        return df

    def _build_target_axis(self, df: pl.DataFrame) -> np.ndarray:
        frame_min = df.select(pl.col("aligned_frame").min()).item()
        frame_max = df.select(pl.col("aligned_frame").max()).item()
        if frame_max == frame_min:
            frame_min -= 0.5
            frame_max += 0.5
        return np.linspace(frame_min, frame_max, self.target_length)

    def _resample_all(
        self, df: pl.DataFrame, selected_groups: Optional[Iterable[str]]
    ) -> Dict[str, List[AggregatedRecord]]:
        subject_col = self.id_cfg["subject"]
        velocity_col = self.id_cfg["velocity"]
        trial_col = self.id_cfg["trial"]
        group_cols = [subject_col, velocity_col, trial_col]

        records: Dict[str, List[AggregatedRecord]] = {k: [] for k in self.config["signal_groups"]}
        groups = df.group_by(group_cols, maintain_order=True)
        for key, subdf in groups:
            subdf_sorted = subdf.sort("aligned_frame")
            meta = {
                subject_col: key[0],
                velocity_col: float(key[1]),
                trial_col: int(key[2]),
            }
            for group_name, cfg in self.config["signal_groups"].items():
                if selected_groups and group_name not in selected_groups:
                    continue
                data = self._interpolate_group(subdf_sorted, cfg["columns"])
                records[group_name].append(
                    AggregatedRecord(
                        subject=meta[subject_col],
                        velocity=meta[velocity_col],
                        trial=meta[trial_col],
                        data=data,
                    )
                )
        return records

    def _interpolate_group(self, df: pl.DataFrame, columns: List[str]) -> Dict[str, np.ndarray]:
        assert self.target_axis is not None, "target_axis must be initialized before interpolation"
        x = df["aligned_frame"].to_numpy()
        data: Dict[str, np.ndarray] = {}
        for col in columns:
            y = df[col].to_numpy()
            valid = ~(np.isnan(x) | np.isnan(y))
            if valid.sum() < 2:
                data[col] = np.full_like(self.target_axis, np.nan, dtype=float)
                continue
            f = interp1d(
                x[valid],
                y[valid],
                kind=self.interp_method,
                bounds_error=False,
                fill_value=np.nan,
                assume_sorted=True,
            )
            data[col] = f(self.target_axis)
        return data

    def _run_mode(self, signal_group: str, mode_name: str, mode_cfg: Dict) -> None:
        records = self.resampled.get(signal_group, [])
        if not records:
            return

        filtered_records = self._apply_filter(records, mode_cfg.get("filter"))
        if not filtered_records:
            return

        group_fields = mode_cfg.get("groupby", [])
        grouped = self._group_records(filtered_records, group_fields)

        for key, recs in grouped.items():
            aggregated = self._aggregate_group(recs)
            filename = self._render_filename(mode_cfg["filename_pattern"], key, signal_group, group_fields)
            output_dir = Path(self.base_dir, mode_cfg["output_dir"])
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / filename
            markers = self._collect_markers(signal_group, key, group_fields, mode_cfg.get("filter"))
            self._plot(signal_group, aggregated, output_path, key, mode_name, group_fields, markers)

    def _apply_filter(
        self, records: List[AggregatedRecord], filter_cfg: Optional[Dict]
    ) -> List[AggregatedRecord]:
        if not filter_cfg:
            return records
        col = filter_cfg["column"]
        value = filter_cfg["value"]
        return [r for r in records if getattr(r, col, None) == value]

    def _group_records(
        self, records: List[AggregatedRecord], group_fields: List[str]
    ) -> Dict[Tuple, List[AggregatedRecord]]:
        if not group_fields:
            return {("all",): records}

        grouped: Dict[Tuple, List[AggregatedRecord]] = {}
        for rec in records:
            key = tuple(getattr(rec, f) for f in group_fields)
            grouped.setdefault(key, []).append(rec)
        return grouped

    def _aggregate_group(self, records: List[AggregatedRecord]) -> Dict[str, np.ndarray]:
        assert records, "No records to aggregate"
        channels = records[0].data.keys()
        aggregated: Dict[str, np.ndarray] = {}
        for ch in channels:
            stack = np.vstack([r.data[ch] for r in records])
            nan_template = np.full_like(self.target_axis, np.nan, dtype=float)  # type: ignore[arg-type]
            if np.all(np.isnan(stack)):
                aggregated[ch] = nan_template
            else:
                nan_cols = np.all(np.isnan(stack), axis=0)
                if (~nan_cols).any():
                    nan_template[~nan_cols] = np.nanmean(stack[:, ~nan_cols], axis=0)
                aggregated[ch] = nan_template
        return aggregated

    def _render_filename(
        self, pattern: str, key: Tuple, signal_group: str, group_fields: List[str]
    ) -> str:
        if key == ("all",):
            return pattern.format(signal_group=signal_group)
        mapping = {field: value for field, value in zip(group_fields, key)}
        mapping["signal_group"] = signal_group
        return pattern.format(**mapping)

    def _plot(
        self,
        signal_group: str,
        aggregated: Dict[str, np.ndarray],
        output_path: Path,
        key: Tuple,
        mode_name: str,
        group_fields: List[str],
        markers: Dict[str, Any],
    ) -> None:
        if signal_group == "emg":
            self._plot_emg(aggregated, output_path, key, mode_name, group_fields, markers)
        elif signal_group == "forceplate":
            self._plot_forceplate(aggregated, output_path, key, mode_name, group_fields, markers)
        elif signal_group == "cop":
            self._plot_cop(aggregated, output_path, key, mode_name, group_fields, markers)

    def _plot_emg(
        self,
        aggregated: Dict[str, np.ndarray],
        output_path: Path,
        key: Tuple,
        mode_name: str,
        group_fields: List[str],
        markers: Dict[str, Any],
    ) -> None:
        rows, cols = self.config["signal_groups"]["emg"]["grid_layout"]
        fig, axes = plt.subplots(rows, cols, figsize=EMG_STYLE["figsize"], dpi=COMMON_STYLE["dpi"])
        axes_flat = axes.flatten()
        x = self.target_axis
        channels = self.config["signal_groups"]["emg"]["columns"]
        for ax, ch in zip(axes_flat, channels):
            y = aggregated.get(ch)
            if y is None:
                ax.axis("off")
                continue
            ax.plot(
                x,
                y,
                EMG_STYLE["line_color"],
                linewidth=EMG_STYLE["line_width"],
                alpha=EMG_STYLE["line_alpha"],
                label=ch,
            )
            for name, (start, end) in self.window_frames.items():
                ax.axvspan(start, end, color=WINDOW_COLORS.get(name, "#cccccc"), alpha=EMG_STYLE["window_span_alpha"])
            marker_info = markers.get(ch, {})
            onset_time = marker_info.get("onset")
            if onset_time is not None:
                ax.axvline(onset_time, **EMG_STYLE["onset_marker"], label="onset")
            max_time = marker_info.get("max")
            if max_time is not None:
                ax.axvline(max_time, **EMG_STYLE["max_marker"], label="max")
            ax.set_title(ch, fontsize=COMMON_STYLE["title_fontsize"], fontweight=COMMON_STYLE["title_fontweight"], pad=COMMON_STYLE["title_pad"])
            ax.grid(True, alpha=COMMON_STYLE["grid_alpha"])
            ax.tick_params(labelsize=COMMON_STYLE["tick_labelsize"])
            ax.legend(fontsize=EMG_STYLE["legend_fontsize"], loc=COMMON_STYLE["legend_loc"], framealpha=COMMON_STYLE["legend_framealpha"])
        for ax in axes_flat[len(channels) :]:
            ax.axis("off")
        fig.suptitle(self._format_title(signal_group="emg", mode_name=mode_name, group_fields=group_fields, key=key), fontsize=COMMON_STYLE["title_fontsize"], fontweight=COMMON_STYLE["title_fontweight"])
        fig.supxlabel(EMG_STYLE["x_label"], fontsize=COMMON_STYLE["label_fontsize"])
        fig.supylabel("Amplitude", fontsize=COMMON_STYLE["label_fontsize"])
        fig.tight_layout(rect=COMMON_STYLE["tight_layout_rect"])
        fig.savefig(output_path, bbox_inches=COMMON_STYLE["savefig_bbox_inches"], facecolor=COMMON_STYLE["savefig_facecolor"])
        plt.close(fig)

    def _plot_forceplate(
        self,
        aggregated: Dict[str, np.ndarray],
        output_path: Path,
        key: Tuple,
        mode_name: str,
        group_fields: List[str],
        markers: Dict[str, Any],
    ) -> None:
        rows, cols = self.config["signal_groups"]["forceplate"]["grid_layout"]
        fig, axes = plt.subplots(rows, cols, figsize=FORCEPLATE_STYLE["figsize"], dpi=COMMON_STYLE["dpi"])
        x = self.target_axis
        for ax, ch in zip(np.ravel(axes), self.config["signal_groups"]["forceplate"]["columns"]):
            y = aggregated[ch]
            color = FORCEPLATE_STYLE["line_colors"].get(ch, "blue")
            ax.plot(x, y, color=color, linewidth=FORCEPLATE_STYLE["line_width"], alpha=FORCEPLATE_STYLE["line_alpha"], label=ch)
            for name, (start, end) in self.window_frames.items():
                ax.axvspan(start, end, color=WINDOW_COLORS.get(name, "#cccccc"), alpha=FORCEPLATE_STYLE["window_span_alpha"])
            onset_time = markers.get(ch, {}).get("onset")
            if onset_time is not None:
                ax.axvline(onset_time, **FORCEPLATE_STYLE["onset_marker"], label="onset")
            ax.set_title(ch, fontsize=COMMON_STYLE["title_fontsize"], fontweight=COMMON_STYLE["title_fontweight"], pad=COMMON_STYLE["title_pad"])
            ax.grid(True, alpha=COMMON_STYLE["grid_alpha"])
            ax.tick_params(labelsize=COMMON_STYLE["tick_labelsize"])
            ax.legend(fontsize=FORCEPLATE_STYLE["legend_fontsize"], loc=COMMON_STYLE["legend_loc"], framealpha=COMMON_STYLE["legend_framealpha"])
            ax.set_xlabel(FORCEPLATE_STYLE["x_label"], fontsize=COMMON_STYLE["label_fontsize"])
            ax.set_ylabel(f"{ch} Value", fontsize=COMMON_STYLE["label_fontsize"])
        fig.suptitle(self._format_title(signal_group="forceplate", mode_name=mode_name, group_fields=group_fields, key=key), fontsize=COMMON_STYLE["title_fontsize"], fontweight=COMMON_STYLE["title_fontweight"])
        fig.tight_layout(rect=COMMON_STYLE["tight_layout_rect"])
        fig.savefig(output_path, bbox_inches=COMMON_STYLE["savefig_bbox_inches"], facecolor=COMMON_STYLE["savefig_facecolor"])
        plt.close(fig)

    def _plot_cop(
        self,
        aggregated: Dict[str, np.ndarray],
        output_path: Path,
        key: Tuple,
        mode_name: str,
        group_fields: List[str],
        markers: Dict[str, Dict[str, float]],
    ) -> None:
        cx = aggregated.get("Cx")
        cy = aggregated.get("Cy")
        if cx is None or cy is None:
            return
        x_vals = cx
        y_vals = -cy if COP_STYLE["y_invert"] else cy
        fig, ax = plt.subplots(1, 1, figsize=COP_STYLE["figsize"], dpi=COMMON_STYLE["dpi"])
        ax.scatter(x_vals, y_vals, color=COP_STYLE["background_color"], alpha=COP_STYLE["background_alpha"], s=COP_STYLE["background_size"], label="trajectory")
        for name, (start, end) in self.window_frames.items():
            mask = (self.target_axis >= start) & (self.target_axis <= end)
            if mask.any():
                ax.scatter(
                    x_vals[mask],
                    y_vals[mask],
                    s=COP_STYLE["scatter_size"],
                    alpha=COP_STYLE["scatter_alpha"],
                    color=WINDOW_COLORS.get(name, "#999999"),
                    label=name,
                )
        max_time = markers.get("max")
        if max_time is not None:
            idx = self._closest_index(self.target_axis, max_time)
            ax.scatter(
                x_vals[idx],
                y_vals[idx],
                s=COP_STYLE["max_marker"]["size"],
                marker=COP_STYLE["max_marker"]["marker"],
                color=COP_STYLE["max_marker"]["color"],
                edgecolor=COP_STYLE["max_marker"]["edgecolor"],
                linewidth=COP_STYLE["max_marker"]["linewidth"],
                zorder=COP_STYLE["max_marker"]["zorder"],
                label="max",
            )
        ax.grid(True, alpha=COMMON_STYLE["grid_alpha"])
        ax.tick_params(labelsize=COMMON_STYLE["tick_labelsize"])
        ax.legend(fontsize=COP_STYLE["legend_fontsize"], loc=COMMON_STYLE["legend_loc"], framealpha=COMMON_STYLE["legend_framealpha"])
        ax.set_xlabel(COP_STYLE["x_label"], fontsize=COMMON_STYLE["label_fontsize"])
        ax.set_ylabel(COP_STYLE["y_label"], fontsize=COMMON_STYLE["label_fontsize"])
        ax.set_aspect("equal", adjustable="box")
        fig.suptitle(self._format_title(signal_group="cop", mode_name=mode_name, group_fields=group_fields, key=key), fontsize=COMMON_STYLE["title_fontsize"], fontweight=COMMON_STYLE["title_fontweight"])
        fig.tight_layout(rect=COMMON_STYLE["tight_layout_rect"])
        fig.savefig(output_path, bbox_inches=COMMON_STYLE["savefig_bbox_inches"], facecolor=COMMON_STYLE["savefig_facecolor"])
        plt.close(fig)

    def _compute_window_frames(self) -> Dict[str, Tuple[float, float]]:
        frames = {}
        definitions = self.config.get("windows", {}).get("definitions", {})
        for name, cfg in definitions.items():
            # Convert ms offsets relative to onset into device-frame units for plotting.
            start = cfg["start_ms"] * self.device_rate / 1000
            end = cfg["end_ms"] * self.device_rate / 1000
            frames[name] = (start, end)
        return frames

    def _format_title(
        self, signal_group: str, mode_name: str, group_fields: List[str], key: Tuple
    ) -> str:
        if key == ("all",):
            return f"{mode_name} | {signal_group}"
        parts = [f"{field}={value}" for field, value in zip(group_fields, key)]
        return f"{mode_name} | {signal_group} | " + ", ".join(parts)

    def _collect_markers(
        self,
        signal_group: str,
        key: Tuple,
        group_fields: List[str],
        filter_cfg: Optional[Dict],
    ) -> Dict[str, Any]:
        if self.features_df is None:
            return {}
        df = self.features_df
        if filter_cfg:
            col = filter_cfg["column"]
            val = filter_cfg["value"]
            if col in df.columns:
                df = df.filter(pl.col(col) == val)
        for field, value in zip(group_fields, key):
            if field in df.columns:
                df = df.filter(pl.col(field) == value)
        if df.is_empty():
            return {}
        if signal_group == "emg":
            return self._collect_emg_markers(df)
        if signal_group == "forceplate":
            return self._collect_forceplate_markers(df)
        if signal_group == "cop":
            return self._collect_cop_markers(df)
        return {}

    def _collect_emg_markers(self, df: pl.DataFrame) -> Dict[str, Dict[str, float]]:
        channels = self.config["signal_groups"]["emg"]["columns"]
        onset_cols = [
            "TKEO_AGLR_emg_onset_timing",
            "TKEO_TH_emg_onset_timing",
            "non_TKEO_TH_onset_timing",
        ]
        markers: Dict[str, Dict[str, float]] = {}
        for ch in channels:
            ch_df = df.filter(pl.col("emg_channel") == ch)
            if ch_df.is_empty():
                continue
            onset_val = None
            for col in onset_cols:
                if col in ch_df.columns:
                    onset_val = self._safe_mean(ch_df[col])
                    if onset_val is not None:
                        break
            max_val = self._safe_mean(ch_df["emg_max_amp_timing"]) if "emg_max_amp_timing" in ch_df.columns else None
            marker_info: Dict[str, float] = {}
            if onset_val is not None:
                marker_info["onset"] = onset_val
            if max_val is not None:
                marker_info["max"] = max_val
            if marker_info:
                markers[ch] = marker_info
        return markers

    def _collect_forceplate_markers(self, df: pl.DataFrame) -> Dict[str, Dict[str, float]]:
        mapping = {"Fx": "fx_onset_timing", "Fy": "fy_onset_timing", "Fz": "fz_onset_timing"}
        markers: Dict[str, Dict[str, float]] = {}
        for ch, col in mapping.items():
            if col in df.columns:
                onset_val = self._safe_mean(df[col])
                if onset_val is not None:
                    markers[ch] = {"onset": onset_val}
        return markers

    def _collect_cop_markers(self, df: pl.DataFrame) -> Dict[str, Dict[str, float]]:
        timing_cols = [
            "cop_max_timing_p1",
            "cop_max_timing_p2",
            "cop_max_timing_p3",
            "cop_max_timing_p4",
        ]
        for col in timing_cols:
            if col in df.columns:
                val = self._safe_mean(df[col])
                if val is not None:
                    return {"max": val}
        return {}

    @staticmethod
    def _safe_mean(series: pl.Series) -> Optional[float]:
        val = series.drop_nulls().mean()
        if val is None or np.isnan(val):
            return None
        return float(val)

    @staticmethod
    def _closest_index(arr: np.ndarray, value: float) -> int:
        return int(np.nanargmin(np.abs(arr - value)))

    def _load_features(self) -> Optional[pl.DataFrame]:
        features_path = self.config["data"].get("features_file")
        if not features_path:
            return None
        path = Path(features_path)
        if not path.is_absolute():
            path = (self.base_dir / path).resolve()
        if not path.exists():
            return None
        df = pl.read_csv(path)
        df = df.rename({c: c.lstrip("\ufeff") for c in df.columns})
        return df


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Aggregated signal visualization")
    default_config = Path(__file__).resolve().parent / "config.yaml"
    parser.add_argument("--config", type=str, default=str(default_config), help="Path to YAML config.")
    parser.add_argument(
        "--modes",
        type=str,
        nargs="*",
        default=None,
        help="Aggregation modes to run (default: all enabled).",
    )
    parser.add_argument(
        "--groups",
        type=str,
        nargs="*",
        default=None,
        help="Signal groups to run (default: all).",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    visualizer = AggregatedSignalVisualizer(Path(args.config))
    ensure_output_dirs(visualizer.base_dir, visualizer.config)
    visualizer.run(modes=args.modes, signal_groups=args.groups)


if __name__ == "__main__":
    main()

```
      </file>
</files>